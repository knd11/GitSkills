### 1.A review of classification algorithms for EEG based brain–computer interfaces: a 10 year update



### 2. Optimizing spatial filter pairs for EEG classification based on phase-synchronization

​	In particular, optimal spatial filters have been designed to classify EEG signals based on band power features. Unfortunately, there are other relevant EEG features for which no optimal spatial filter exists. This is the case for Phase Locking Value (PLV) features, which measure the synchronization between 2 EEG channels.

​	The PLV was introduced in the 1999 as a statistics for detecting synchrony in a precise frequency range between two different recording sites.



### 3. Understanding Brain Connectivity Patterns during Motor Imagery for Brain-Computer Interfacing

​	EEG connectivity measures could provide a new type of feature space for inferring subject’s intention in Brain-Computer Interfaces.



### 4. Entropy and complexity measures for EEG signal classification of schizophrenic and control participants

​	Abrams and Taylor, using a system of classification similar to DSM-IV showed that schizophrenic patients had twice as many left sided temporal EEG abnormalities as patients with affective disorders.

Several ==features== including <u>Shannon entropy, spectral entropy, approximate entropy, Lempel-Ziv complexity and ==Higuchi fractal dimension==(参考下一篇文献)</u> are extracted from EEG signals. Leaveone (participant)-out cross-validation is used for reliable estimate of the separability of the two groups. The training set is used for training the two classifiers, namely,linear discriminant analysis (LDA) and adaptive boosting (Adaboost). Each classifier is assessed using the test dataset.

​	The results agree with most previous works showing that schizophrenic patients are characterized by less complex neurobehavioral and neuropsychological measurements.
$$
L(k)=\sum_{m=1}^{k} L_{m}(k)
$$
This procedure is repeated for each $k$ ranging from 1 to  $k_{max}$, the total average length for delay $k$, L(k), is proportional to $k^{-D}$, where $D$ is the fractal dimension by Higuchi’s method. In the curve of $ln(L(k))$（y轴） versus $ln(1/k)$ （x轴）, the slope of the least squares linear fit is the estimate of the fractal dimension. 

For determination of $k_{max}$, fractal dimension was plotted against different values of $k_{max}$. The point at which the fractal dimension becomes saturated gives an appropriate value for $k_{max}$ . The best result for this study is obtained as $k_{max}=40$.

### 5. Approach to an irregular time series on the basis of the fractal theory

We now consider a finite set of time series observations taken at a regular interval:
$$
X(1), X(2), X(3), \ldots, X(N)
$$
From given time series,we first construct a new time series, $X_{k}^{m}$ ,defined as follows:
$$
X_{k}^{m} ; X(m), X(m+k), X(m+2 k), \ldots, X\left(m+\left[\frac{N-m}{k}\right] \cdot k\right) \quad(m=1,2, \ldots, k)
$$
where [] denotes the Gauss' notation and both k and m are integers.m and k indicate the initial time and the interval time, respectively. For a time interval equal to k, we get k sets of new time series. In the case of k=3 and N=100, three time series obtained by the above process are described as follows:
$$
\begin{array}{l}{X_{3}^{1} ; X(1), X(4), X(7), \ldots, X(97), X(100)} \\ {X_{3}^{2} ; X(2), X(5), X(8), \ldots, X(98)} \\ {X_{3}^{3} ; X(3), X(6), X(9), \ldots, X(99)}\end{array}
$$
We define the length of the curve,$X_{k}^{m}$,as follows:
$$
L_{m}(k)=\left\{\left(\sum_{i=1}^{\frac{N-m}{k}}|X(m+i k)-X(m+(i-1) \cdot k)|\right) \frac{N-1}{\left[\frac{N-m}{k}\right] \cdot k}\right\} / k
$$
The term, $N-1 /([(N-m) / k] \cdot k）$，$k$ represents the normalization factor for the curve length of subset time series. We define the length of the curve for the time interval $k$, $\langle L(k)\rangle$, as the average value over $k$ sets of $\langle L_m(k)\rangle$. If $\langle L(k)\rangle \propto k^{-D}$, then the curve is fractal with the dimension D.
To test that our method for determining a fractal dimension is valid, we show numerical application to simulated data. First, we apply our technique to the simulated data $Y(i)(i=1,2, \ldots, N)$ with the fractal dimension D of 1.5. $Y(i)$ are generated by
$$
Y(i)=\sum_{j=1}^{1000+i} Z(j)
$$
where $Z(j)$ is a Gaussian noise with the mean zero and a standard deviation of 1. The value of 1000 is arbitrarily chosen to eliminate the effect of sampling $Z(1)$ on $Y(1)$. We use the following values of the interval time $k$; $k=1,2,3,4$ and $ k=\left[2^{(j-1) / 4}\right](j=11,12,13, \ldots)$ for $k$ larger than 4, where [] denotes Gauss' notation. The function $\langle L(k)\rangle$ is described as $\langle L(k)\rangle \propto k^{-D}$ for a statistically self-similar curve. Then, if $\langle L(k)\rangle$ is plotted against k on a doubly logarithmic scale, the data should fall on a straight line with a slope $-D$. The logarithm of the length, $log\langle L(k)\rangle$, for a time series $Y(i)$ with $N=2^{17}$, is plotted as a function of $log k$ in fig.1. The value of the vertical axis is multiplied by an arbitrary factor.
The error bar denotes the standard deviation of $\langle L(k)\rangle$. In this calculation, the maximum value of $k$, $k_{max}$ is $2^{11}$.

分形看作具有如下性质的集合：

- 1. F具有精细结构，即在任意小的比例尺度内包含整体。
- 1. F是不规则的，以致于不能用传统的几何语言来描述。
  2. F通常具有某种自相似性，或许是近似的或许是统计意义下的。
  3. F在某种方式下定义的“分维数”通常大于F的拓扑维数。
  4. F的定义常常是非常简单的，或许是递归的。 

分数维的性质

- 分数维一定大于拓扑维而小于它的所占的空间维；
- 分数维数值D的大小是分形对象复杂程度的一个度量，数值越大分形对象越复杂
- 对于各种分形来说，即使在不同的尺度上，用分维表示的不规整程度却是一个常量。

### 6. A new approach for EEG signal classification of schizophrenic and control participants

​	This paper is concerned with a two stage procedure for analysis and classification of electroencephalogram(EEG) signals for twenty schizophrenic patients and twenty age-matched control participants.
​	For each case,20 channels of EEG are recorded. First, the more informative channels are selected using the mutual information techniques. Then, genetic programming is employed to select the best features from the selected channels. Several ==features== including <u>autoregressive model parameters, band power and fractal dimension</u> are used for the purpose of classification. Both linear discriminant analysis (LDA) and adaptive boosting(Adaboost) are trained using tenfold cross validation to classify the reduced feature set and a classification accuracy of 85.90% and 91.94% is obtained by LDA and Adaboost, respectively. Another interesting observation from the channel selection procedure is that most of the selected channels are located in the prefrontal and temporal lobes confirming neuropsychological and neuroanatomical findings. The results obtained by the proposed approach are compared with a one stage procedure, the principal component analysis (PCA)-based feature selection, utilizing only 100 features selected from all channels. It is illustrated that the two stage procedure consisting of channel selection followed by feature reduction gives a more enhanced results in an efficient computation time.



Fractal dimension has a relation to entropy and entropy is directly related to the amount of information inside a signal. Fractal dimension can be interpreted simply as the degree of meandering (roughness or irregularity) in a signal. Here, three methods of fractal dimension calculation are presented.

### 7. Value of amplitude, phase, and coherence features for a sensorimotor rhythm-based brain–computer interface

​	Measures that quantify the relationship between two or more brain signals are drawing attention as neuroscientists explore the mechanisms of large-scale integration that enable coherent behavior and cognition. Traditional Fourier-based ==measures== of <u>coherence</u> have been used to quantify frequency-dependentrelationships between two signals. More recently, several off-line studies examined <u>phase-locking value(PLV)</u> as a possible feature for use in brain-computer interface(BCI) systems. However, only a few indiyiduals have been studied and full statistical comparisons among the different classes of features and their combinations have not been conducted. The present study examines the relative BCI performance of <u>spectral power, coherence, and PLV</u>, alone and in combination. The results indicate that spectral power produced classification at least as good as PLV, coherence, or any possible combination of these measures. This may be due to the fact that all three measures reflect mainly the activity of a single signal source (i.e, an area of sensorimotor cortex). This possibility is supported by the finding that EEG signals from different channels generally had near-zero phase differences. Coherence, PLV, and other measures of inter-channel relationships may be more valuable for BCIs that use signals from more than one distinct cortical source.

  在神经科学研究中，信号间同步性现象是不同区域间信息交流的关键特征，PLV是一个代表性方法，PLV可量化在特定频带和时间区域的两个神经信号进入锁相状态的同步程度。神经科学研究认为，发生了锁相的神经元群体间可以进行有效的信息通讯。因为在锁相状态下，两个神经元群体的信号输入和输出窗可能是同时打开的。

**Phase Locking Value (PLV)** is a statistic that can be used to investigate task-induced changes in long range synchronization of neural activity from EEG data. This method is introduced in Lachaux et al., (1999). I have implemented the computation of this statistic in MATLAB and you can download it [**here**](http://cn.mathworks.com/matlabcentral/fileexchange/31600-phase-locking-value). In this post, I will talk a little bit about how PLV can be useful when analyzing EEG data. Note that this statistic may also be used to quantify LFP (local field potential) data recordings to study synchrony at a finer scale compared to EEG.



It is useful to keep in mind a few properties of the PLV statistic before diving in further.

> 1 PLV statistic is a time course. This means that for every time point in your EEG data, you can extract a measure of connectivity. Therefore, this quantity can be used to observe transient changes in connectivity without pre-defining a time window of analysis.
>
> 2 One PLV time course for every electrode pair. For example, if data is recorded from 28 EEG electrodes, there are 378 possible PLV time courses.
>
> 3 One PLV time course is computed over multiple trials. In practice, I have observed that this metric is suitable for datasets with a large number of trials. It is good to have a few hundred trials for each experimental condition for which long range synchronization is to be quantified using PLV.

The PLV statistic can be argued to be a proxy for connectivity. Intuitively, if the EEG signal in two channels (electrodes) during an experimental condition rises and falls together more than a baseline value, then there is more synchronization or loosely speaking, enhanced connectivity between these two electrodes. If it is less than the baseline value, there is desynchronization or loosely speaking, decreased connectivity between the two electrodes. Note that this metric does not care about the co-variation in the power of the EEG signal between two electrodes.



------

The schematic below illustrates how PLV is computed in this implementation. Explanation for each step follows.

![795056-20170304103532407-324954918.png](https://images2015.cnblogs.com/blog/795056/201703/795056-20170304103532407-324954918.png)

- **Filtering**
  The EEG data is first filtered in the desired frequency band of interest, for example, gamma band, 35-45 Hz. In practice, it is best to use an FIR (finite impulse response) filter to filter such data in comparison to IIR (infinite impulse response) filters. Loosely speaking, ==FIR filters filter the signal in time domain and IIR filters operate in the frequency domain==. Put simply, an FIR filters computes the value of the filtered signal at a time point from the values of the previous and future points. How far the FIR filter looks is knows as the order of the FIR filter. <u>For EEG signals, a useful rule of thumb is to ‘look at’ about 4 to 5 cycles of the desired EEG rhythm</u>. As an example, consider gamma rhythm (35-45 Hz). Here, one cycle is about 25 ms and I would set the order of the filter to be 100 ms. If the sampling rate is 500 Hz, then the filter order would be 50 data points.
- **Hilbert transform**
  This step is used to quantify rising and falling of EEG data. Hilbert transform of a signal can be used to compute the instantaneous amplitude as well as the instantaneous phase. We ignore the former and use the phase (φ) for PLV computation. φ is a value between –π and π. Think of the filtered EEG signal as a series of crests and troughs. A value of π indicates the peak of a crest and a –π indicates the bottom of a trough.
- **PLV metric**
  Remember that there is a phase time course φ for every EEG electrode. Now consider the phase time courses of two electrodes. The difference between these two time courses (Δφ) quantifies locking between the phases of these two electrodes. If an experimental stimulus influences signal in two electrodes to rise and fall together or with a certain lag, then Δφ will be consistent between trials. If there is absolutely no relationship between when the signal in these two electrodes will rise and fall, then Δφ will be random. All we need to do now is to quantify the randomness in Δφ. This can be done using a little trick from complex number theory. Please see the equation in the analysis schematic to understand this trick.
- **Normalization**
  This step is performed to make the PLV metric useful in practice. Note that due to its definition, PLV is always a value between 0 and 1; 0 signifying purely random rise and fall whereas a value of 1 signifies that one signal perfectly follows the other. In practice, the value of a PLV obtained is going to vary very little over time and the absolute PLV is not what we are interested in. We are interested in knowing whether an experimental stimulus induced a change in PLV. We are interesting in answering questions such as “was there increased connectivity between the frontal and parietal electrodes when the subject performed a task?” . To find this, we should test if PLV after stimulus is significantly greater than the PLV before stimulus. To simplify things, we can use the pre-stimulus period as a baseline and perform a z-transform normalization.



### 8. Selection of relevant features for EEG signal classification of schizophrenic patients

In this paper, EEG signals of 20 schizophrenic patients and 20 age-matched control participants are analyzed with the objective of determining the more informative channels and finally distinguishing the two groups. For each case, 22 channels of EEG were recorded. A two-stage feature selection algorithm is designed, such that, the more informative channels are first selected to enhance the discriminative information. Two methods,bidirectional search and plus-L minus-R (LRS) techniques are employed to select these informative channels. The interesting point is that most of selected channels are located in the temporal lobes (containing the limbic system) that confirm the neuro-phychological differences in these areas between the schizophrenic and normal participants. After channel selection, genetic algorithm (GA) is employed to select the best features from the selected channels. In this case, in addition to elimination of the less informative channels, the redundant and less discriminant features are also eliminated. A computationally fast algorithm with excellent classification results is obtained. Implementation of this efficient approach involves several features including autoregressive (AR) model parameters, band power, fractal dimension and wavelet energy. To test the performance of the final subset of features, classifiers including linear discriminant analysis (LDA) and support vector machine (SVM) are employed to classify the reduced feature set of the two groups. Using the bidirectional search for channel selection, a classification accuracy of 84.62% and 99.38% is obtained for LDA and SVM, respectively. Using the LRS technique for channel selection, a classification accuracy of 88.23% and 99.54% is also obtained for LDA and SVM, respectively. Finally, the results are compared and contrasted with two well-known methods namely, the single-stage feature selection (evolutionary feature selection) and principal component analysis (PCA)-based feature selection. The results show improved
accuracy of classification in relatively low computational time with the two-stage feature selection.	



#### 3.2. Band power

​	Normally, in most cases, most waves in the EEG can be classified as alpha, beta, theta and delta waves. The definition of the boundaries between the bands is somewhat arbitrary,however, in most of applications these are defined as:delta = [less than 4 Hz], theta = [4–8 Hz], alpha = [8–13 Hz] and beta = [13–30 Hz]. Alpha waves are rhythmical waves that occur at frequencies between 8 and 13 Hz and are found in the EEGs of almost all adult people when they are awake. When the awake person’s attention is directed to some specific type of mental activity, the alpha waves are replaced by asynchronous,higher frequency beta waves. Beta waves occur at frequencies greater than 13 Hz. Theta waves have frequencies between 4 and 8 Hz. They occur normally in parietal and temporal regions in children, but they also occur during emotional stress in some adults. <u>Theta waves also occur in many brain disorders, often in degenerative brain states.</u> Delta waves include all the waves of the EEG with frequencies less than 4 Hz, and they occur in very deep sleep, in infancy and in serious organic brain disease. Therefore, EEG contains different specific frequency components,which carry the discriminative information. This type of feature reflects the energy in four bands, which are particularly important to classify different brain states. At first, EEG signals are filtered by four Butterworth band pass filters (order five) in 0–4 Hz (delta), 4–8 Hz (theta), 8–13 Hz (alpha) and 13–30 Hz (beta). Then, ==the filtered signals are squared to get power of the signal in each band.== Finally, by applying an average filter, each sample is an ==average== of 250 ms of the last samples.	



- 





### 9. Classification of EEG Signals using adaptive weighted distance nearest neighbor algorithm

	Electroencephalogram (EEG) signals are often used to diagnose diseases such as seizure,

alzheimer, and schizophrenia. One main problem with the recorded EEG samples is that they are not equally reliable due to the ==artifacts== at the time of recording. EEG signal classification algorithms should have a mechanism to handle this issue. It seems that using adaptive classifiers can be useful for the biological signals such as EEG. In this paper, a general adaptive method named weighted distance nearest neighbor (WDNN) is applied for EEG signal classification to tackle this problem. This classification algorithm assigns a weight to each training sample to control its influence in classifying test samples. The weights of training samples are used to find the nearest neighbor of an input query pattern. To assess the performance of this scheme, EEG signals of thirteen schizophrenic patients and eighteen normal subjects are analyzed for the classification of these two groups. Several features including, fractal dimension, band power and autoregressive (AR) model are extracted from EEG signals. The classification results are evaluated using Leave one (subject) out cross validation for reliable estimation. The results indicsate that combination of WDNN and selected features can significantly outperform the basic nearest-neighbor and the other methods proposed in the past for the classification of these two groups. Therefore, this method can be a complementary tool for specialists to distinguish schizophrenia disorder.



### 10. Individual Recognition in Schizophrenia using Deep Learning Methods with Random Forest and Voting Classifiers: Insights from Resting State EEG Streams

Recently, there has been a growing interest in <u>monitoring brain activity for individual recognition system</u>. So far these works are mainly focussing on single channel data or fragment data collected by some advanced brain monitoring modalities. In this study we propose new individual recognition schemes based on spatio-temporal resting state Electroencephalography (EEG) data. Besides, <u>instead of using features derived from artificially-designed procedures, modified deep learning architectures which aim to automatically extract an individual’s unique features are developed to condut classification</u>. Our designed deep learning frameworks are proved of a small but consistent advantage of replacing the softmax layer with Random Forest. Additionally, a voting layer is added at the top of designed neural networks in order to tackle the classification problem arisen from EEG streams. Lastly, various experiments are implemented to evaluate the performance of the designed deep learning architectures; Results indicate that the proposed EEG-based individual recognition scheme yields a high degree of classification accuracy: 81.6% for characteristics in high risk (CHR) individuals, 96.7% for clinically stable first episode patients with schizophrenia (FES) and 99:2% for healthy
controls (HC).	

1.1. Diagnosis of schizophrenia
Schizophrenia is ==diagnosed== primarily using diagnostic criteria from the ==Diagnostic and Statistical Manual of Mental Disorders (DSM-5)==, by asking patients a series of questions to elicit information such as duration of illness and clinical symptoms (American Psychiatric Association, 2013). The clinical symptom ==severity== of schizophrenia is measured using clinical scales such as the ==Positive and Negative Syndrome Scale (PANSS)== (Kay et al., 1988). Various diagnostic tools can help psychiatrists and clinical psychologists diagnose schizophrenia, but traditional clinical diagnoses might be sometimes inaccurate because schizophrenia patients sometimes intentionally <u>hide their symptoms</u>, and even experts sometimes have difficulty differentiating schizophrenia from other mental illnesses due to similar symptoms (Lindstrom et al.,1994; McGorry et al., 1995; Norman et al., 1996).Thus, many researchers have sought to <u>develop objective, quantitative biomarkers that can enhance the overall accuracy of diagnosis with the aid of neuroimaging technologies</u>.

Among a variety of neuroimaging modalities,electroencephalography (EEG) is regarded as one of the most useful, thanks to its high temporal resolution and lowcost.



### 11.A Novel Convolutional Neural Networks for Emotion Recognition Based on EEG Signal

Emotion recognition based on electroencephalogram (EEG) signal is attracting more and more attention. Many feature engineering based models have been investigated. However, these models require a lot of effort for manually designing feature set. And these features can be hardly transformed among different problems. To reduce the manual effort on features used in EEG-based recognition and improve the performance, we propose an end-to-end model which is based on Convolutional Neural Networks (CNNs). In order to represent the EEG signals better, the original channels of EEG are firstly rearranged by Pearson Correlation Coefficient and the rearranged EEGs are fed into CNN. experiments were carried on DEAP dataset. The experimental results on the DEAP dataset show that the proposed method achieves 77.98% accuracy on the Valence recognition and 72.98% on the Arousal recognition.



CNNs is a kind of End-to-End models. The End-to-End models based on deep neural network learn the mapping from the original input to the expected output effectively through the deep neural network. It avoids the complicated manually feature design and selection. But using CNNs in EEG emotion recognition directly can hardly achieve an ideal result. ==The reason is that the order of channels of input which fed into CNNs need to be meaningful. However, the original EEG channels are not arranged their orders according to their characteristic==. The proximity of the channels do not reflect the value of the relevant information between the channels. Therefore, the strategy of increasing the amount of information on adjacent channels by channel rearrangement will help CNNs to learn more effectively.Meanwhile, Pearson correlation coefficient features can represent the connectivity information between different EEG signal channels.



The features used in emotion recognition based on EEG can be mainly classified into ==time domain features, frequency domain features,time-frequency domain features, spatial distribution features of EEG signals and brain network features==.
The time domain features include simple signal statistics, Hjorth index, non-stationary index and etc. These ==time domain== features often have the characteristics of strong time-sensitive but poor anti-noise. The frequency domain features include different frequency spectrum power [4], short time Fourier transform feature(STFT)[5], wavelet analysis feature [6] and so on. The main characteristics of ==frequency domain== feature are relatively strong anti-noise ability. But the complexity of algorithm using frequency domain features is usually too high and the operation cost is expensive. The ==Spatial distribution== features use Channel Connectivity (FunctionalConnectivity) characteristics of the EEG signal. You-Yun Leeand his colleagues firstly use channel correlation, channel coherence and Phase synchronization index to take out emotional recognition based on EEG signal, which achieved a very good performance [7]. The Spatial distribution features <u>can effectively exploit the characteristics of EEG signal, and have the characteristics of low computational cost and strong anti-
interference ability</u>. The brain network features include Pearson correlation coefficient features and Mutual Information [8].



==The CNNs can avoid the complex process of feature design and feature extraction. But use CNNs for emotion recognition directly can hardly achieve an satifified performance. To improve the ability of CNNs, we use Pearson correlationcoefficient to rearrange signal channels involving the information of adjacent channels==. Then Pearson correlation coefficient features are combined with CNNs to introduce theinformation of long-distance channels. Finally, we use a feed-forward network to identify EEG emotion.



### 12. Selection of relevant features for EEG signal classification of schizophrenic patients

<u>In this paper, EEG signals of 20 schizophrenic patients and 20 age-matched control participants are analyzed with the obiective of determining the more informative channels and finally distinguishing the two groups. For each case,22 channels of EEG were recorded</u>.A two-stage feature selection algorithm is designed, such that, the more informative channels are first selected to enhance the discriminative information. Two methods, bidirectional search and plus-L minus-R(LRS) techniques are employed to select these informative channels. The interesting point is that most of selected channels are located in the temporal lobes(containing the limbic system) that confirm the neuro-phychological differences in these areasbetween the schizophrenic and normal participants. After channel selection, genetic al gorithm(GA) is employed to select the best features from theselected channels. In this case, in addition to elimination of the less informative channels, the redundant and less discriminant features are alsoeliminated.A computationally fast algorithm with excellent classification results is obtained. Implementation of this efficient approach involves several features including autoregressive(AR) model parameters, band power, fractal dimension and wavelet energy. To test the performance of thefinal subset of features, classifiers including linear discriminant analysis(LDA) and support vector machine (SVM) are employed to classify thereduced feature set of the two groups. Using the bidirectional search for channel selection,a classification accuracy of 84.62% and ==99.38%== is obtained for LDA and SVM, respectively. Using the LRS technique for channel selection,a classification accuracy of 88.23% and ==99.54==% is also obtained for LDA and SVM, respectively. Finally, the results are compared and contrasted with two well-known methods namely, the single-stage feature selection (evolutionary feature selection) and principal component analysis (PCA)-based feature selection. The results show improved accuracy of classification in relatively low computational time with the two-stage feature selection.

==The results obtained showed that the time series generated by schizophrenic patients had a lower complexity than those for the control group==.

Four types of feature extraction methods are used in this study, these are autoregressive (AR) model coefficients ,band power, fractal dimension and wavelet energy.

### 13.Deep Convolutional Neural Network Model for Automated Diagnosis of Schizophrenia Using EEG Signals

A computerized detection system for the diagnosis of Schizophrenia(SZ) using a convolutional neural system is described in this study. Schizophrenia is an anomaly in the brain characterized by behavioral symptoms such as hallucinations and disorganized speech.Electroencephalograms (EEG) indicate brain disorders and are prominently used to study braindiseases. We collected EEG signals from 14 healthy subjects and 14 SZ patients and developed an eleven-layered convolutional neural network(CNN) model to analyze the signals. Conventional machine learning techniques are often laborious and subject to intra-observer variability. Deep learning algorithms that have the ability to automatically extract significant features and classify them are thus employed in this study. Features are extracted automatically at the convolution stage, with the most significant features extracted at the max-pooling stage, and the fully connected layer is utilized to classify the signals. The proposed model generated classification accuracies of ==98.07%== and 81.26% for non-subject based testing and subject based testing, respectively. The developed model can likely aid clinicians as a diagnostic tool to detect early stages of SZ.





















